{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f80ae4f-9aaf-49a4-8213-99c48bd3e30f",
   "metadata": {},
   "source": [
    "# Paso 1: localizar el Excel y listar hojas\n",
    "\n",
    "Objetivo de este paso:\n",
    "1) Comprobar que Python ve el archivo Excel correcto.\n",
    "2) Listar los nombres de las hojas **exactamente** como los detecta `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec7fe0ae-b5b8-4737-9d12-94cd9e2d840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Existe el archivo?: True\n",
      "Ruta absoluta: C:\\Users\\manue\\TFM MÁSTER BIOINFORMÁTICA\\Datos Brasil, España, Mexico.xlsx\n",
      "Hojas detectadas: ['Mexico', 'Brazil', 'Spain']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Opciones de visualización (solo para que se vea cómodo)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# 1) Ruta del Excel (debe estar en la misma carpeta del notebook)\n",
    "xlsx_path = Path(\"Datos Brasil, España, Mexico.xlsx\")\n",
    "\n",
    "print(\"¿Existe el archivo?:\", xlsx_path.exists())\n",
    "print(\"Ruta absoluta:\", xlsx_path.resolve())\n",
    "\n",
    "# 2) Listar hojas\n",
    "xls = pd.ExcelFile(xlsx_path)\n",
    "sheet_names = xls.sheet_names\n",
    "print(\"Hojas detectadas:\", sheet_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba16927-7e80-4b7d-8e63-930246c863c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Paso 2: Cargar las hojas del Excel a DataFrames\r\n",
    "\r\n",
    "En este paso vamos a leer las tres hojas detectadas:\r\n",
    "- `Mexico` → contiene 70 pacientes.\r\n",
    "- `Brazil` → contiene 220 pacientes (143 de Brasil y 77 de España).\r\n",
    "- `Spain` → está vacía.\r\n",
    "\r\n",
    "**Objetivo de este paso:**  \r\n",
    "1. Confirmar cuántas filas y columnas tiene cada hoja.  \r\n",
    "2. Verificar que la hoja `Spain` realmente está vacía.  \r\n",
    "\r\n",
    "No hacemos limpieza ni cambios todavía, solo lectura y revisión del tamaño.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892d58a4-e3ba-455b-b460-9363df34be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mexico: (70, 73)\n",
      "Brazil: (220, 73)\n",
      "Spain: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Cargar hojas\n",
    "df_mexico_raw = pd.read_excel(xlsx_path, sheet_name=\"Mexico\")\n",
    "df_brazil_raw = pd.read_excel(xlsx_path, sheet_name=\"Brazil\")\n",
    "df_spain_raw  = pd.read_excel(xlsx_path, sheet_name=\"Spain\")\n",
    "\n",
    "print(\"Mexico:\", df_mexico_raw.shape)\n",
    "print(\"Brazil:\", df_brazil_raw.shape)\n",
    "print(\"Spain:\", df_spain_raw.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c6cf3a-bfab-4092-b755-7db33a9be36d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Paso 3: Limpieza mínima de **nombres de columnas**\r\n",
    "\r\n",
    "**Por qué hacerlo ahora:**\r\n",
    "- Evita errores tipo `KeyError` por **espacios dobles** o **espacios al final** (ej. `\"Platelets \"`).\r\n",
    "- Facilita que las equivalencias México↔Brasil funcionen sin sorpresas.\r\n",
    "- No tocamos contenidos ni unidades (mg/dL, ng/mL…) todavía; **solo** limpiamos espacios.\r\n",
    "\r\n",
    "**Qué haremos:**\r\n",
    "1) Colapsar espacios múltiples a un único espacio.\r\n",
    "2) Quitar espacios al principio y al final.\r\n",
    "3) Aplicarlo **por igual** a `df_mexico_raw` y `df_brazil_raw`.\r\n",
    "\r\n",
    "Al final veremos **cuántos nombres han cambiado** y un pequeño listado de ejemplos para confirmar que todo está bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7d8795-3dcb-45e7-9f45-c9d15a282b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cambios en nombres (México): 6\n",
      "[(' HCQ use (mg/day)', 'HCQ use (mg/day)'), ('Weight  (kg)', 'Weight (kg)'), ('VLDL (mg/dL) ', 'VLDL (mg/dL)'), ('Platelets ', 'Platelets'), ('VCM ', 'VCM'), ('CHCM ', 'CHCM')]\n",
      "\n",
      "Cambios en nombres (Brasil): 8\n",
      "[(' HCQ use (mg/day)', 'HCQ use (mg/day)'), ('SLEDAI ', 'SLEDAI'), ('Weight  (kg)', 'Weight (kg)'), ('VLDL (mg/dL) ', 'VLDL (mg/dL)'), ('Triglycerides (mg/dL) ', 'Triglycerides (mg/dL)'), ('Reactive C protein  (mg/dl)', 'Reactive C protein (mg/dl)'), ('VCM ', 'VCM'), ('CHCM ', 'CHCM')]\n",
      "\n",
      "Comprobación rápida (nombres que contienen 'platelet' o 'weight'):\n",
      "['Platelets', 'Weight (kg)']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def clean_col_spaces(df: pd.DataFrame) -> tuple[pd.DataFrame, list]:\n",
    "    \"\"\"Devuelve (df_limpio, lista_de_cambios) donde lista_de_cambios son pares (antes, después).\"\"\"\n",
    "    old_cols = list(map(str, df.columns))\n",
    "    new_cols = [re.sub(r\"\\s+\", \" \", c).strip() for c in old_cols]\n",
    "    changes = [(o, n) for o, n in zip(old_cols, new_cols) if o != n]\n",
    "    return df.rename(columns=dict(zip(old_cols, new_cols))), changes\n",
    "\n",
    "# Aplicar a ambas hojas (Spain está vacía, la ignoramos)\n",
    "df_mexico = df_mexico_raw.copy()\n",
    "df_brazil = df_brazil_raw.copy()\n",
    "\n",
    "df_mexico, changes_mx = clean_col_spaces(df_mexico)\n",
    "df_brazil, changes_br = clean_col_spaces(df_brazil)\n",
    "\n",
    "print(f\"Cambios en nombres (México): {len(changes_mx)}\")\n",
    "print(changes_mx[:10])  # mostramos solo los 10 primeros si hay muchos\n",
    "\n",
    "print(f\"\\nCambios en nombres (Brasil): {len(changes_br)}\")\n",
    "print(changes_br[:10])\n",
    "\n",
    "# Comprobación rápida: que 'Platelets' NO termine en espacio, y que 'Weight (kg)' no tenga dobles espacios\n",
    "suspects = [c for c in df_mexico.columns if \"platelet\" in c.lower() or \"weight\" in c.lower()] + \\\n",
    "           [c for c in df_brazil.columns if \"platelet\" in c.lower() or \"weight\" in c.lower()]\n",
    "print(\"\\nComprobación rápida (nombres que contienen 'platelet' o 'weight'):\")\n",
    "print(sorted(set(suspects)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b574b-5e05-4377-aaba-c6e87193bd69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Paso 4: Estandarizar nombres equivalentes (MX ↔ BR)\n",
    "\n",
    "**Objetivo:** Unificar *nombres* que representan la misma variable pero difieren por mayúsculas, espacios o pequeñas variantes.\n",
    "> Aún **no** tocamos tipos de datos ni unidades; solo nombres.\n",
    "\n",
    "**Casos incluidos:**\n",
    "- Age (Years) ↔ Age (years)\n",
    "- smoking habits ↔ Smoking habits\n",
    "- Total Cholesterol ↔ Total cholesterol\n",
    "- Triglycerides (con/sin espacio final)\n",
    "- Uric/Creatinine/Urea (mg/dL vs mg/dl) → normalizamos a **mg/dL** en el nombre\n",
    "- Folic/Vitamin D (ng/mL vs ng/ml) → normalizamos a **ng/mL** en el nombre\n",
    "- Bone mass (kg/Kg)\n",
    "- VLDL (espacio)\n",
    "- SLEDAI (Mex-SLEDAI) ↔ SLEDAI\n",
    "- SLICC_ACR ↔ SLICC\n",
    "- CRP: \"C reactive protein (mg/L)\" ↔ \"Reactive C protein (mg/dl)\" → nombre canónico **C-reactive protein** (la **unidad** la gestionaremos después)\n",
    "\n",
    "**Comprobación al final:**  \n",
    "Listar qué columnas quedan **solo en México** y **solo en Brasil** tras renombrar.  \n",
    "Idealmente, solo deberían quedar los **identificadores** distintos (Folio/Grupo vs Patient/RGHC).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be0b7c5-410f-4195-af19-caec478dabfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas solo en México: 4 ['Albumin (g/dL)', 'Folio', 'Grupo', 'Time of the disease (years)']\n",
      "Columnas solo en Brasil: 4 ['Albumin /d/dl)', 'Patient', 'RGHC', 'Time of disease (years)']\n"
     ]
    }
   ],
   "source": [
    "# 1) Diccionario de equivalencias (solo nombres)\n",
    "column_equivalences = {\n",
    "    # Estándar de mayúsculas/espacios/typos\n",
    "    \"Age (Years)\": \"Age (years)\",\n",
    "    \"smoking habits\": \"Smoking habits\",\n",
    "    \"Total Cholesterol (mg/dL)\": \"Total cholesterol (mg/dL)\",\n",
    "    \"Triglycerides (mg/dL) \": \"Triglycerides (mg/dL)\",\n",
    "    \"Tryglicerides (mg/dL)\": \"Triglycerides (mg/dL)\",\n",
    "\n",
    "    # Unidades en el nombre (normalizamos a mg/dL, ng/mL)\n",
    "    \"Uric Acid (mg/dL)\": \"Uric acid (mg/dL)\",\n",
    "    \"Uric acid (mg/dl)\": \"Uric acid (mg/dL)\",\n",
    "    \"Creatinine (mg/dL)\": \"Creatinine (mg/dL)\",\n",
    "    \"Creatinine (mg/dl)\": \"Creatinine (mg/dL)\",\n",
    "    \"Urea (mg/dL)\": \"Urea (mg/dL)\",\n",
    "    \"Urea (mg/dl)\": \"Urea (mg/dL)\",\n",
    "    \"Folic Acid (ng/mL)\": \"Folic acid (ng/mL)\",\n",
    "    \"Folic acid (ng/ml)\": \"Folic acid (ng/mL)\",\n",
    "    \"Vitamin D (ng/mL)\": \"Vitamin D (ng/mL)\",\n",
    "    \"Vitamin D (ng/ml)\": \"Vitamin D (ng/mL)\",\n",
    "    \"Bone mass (Kg)\": \"Bone mass (kg)\",\n",
    "\n",
    "    # CRP y VLDL\n",
    "    \"Reactive C protein (mg/dl)\": \"C-reactive protein\",\n",
    "    \"C reactive protein (mg/L)\": \"C-reactive protein\",\n",
    "    \"VLDL (mg/dL)\": \"VLDL (mg/dL)\",  # por si acaso tras limpieza\n",
    "    # Diferenciales y scores\n",
    "    \"SLEDAI (Mex-SLEDAI)\": \"SLEDAI\",\n",
    "    \"SLEDAI\": \"SLEDAI\",\n",
    "    \"SLICC_ACR\": \"SLICC\",\n",
    "    \"SLICC\": \"SLICC\",\n",
    "    # Leucocitos diferenciales (unidad la veremos luego)\n",
    "    \"Neutrophils (%)\": \"Neutrophils\",\n",
    "    \"Lymphocytes (%)\": \"Lymphocytes\",\n",
    "    \"Monocytes (%)\": \"Monocytes\",\n",
    "}\n",
    "\n",
    "# 2) Aplicar a copias estandarizadas\n",
    "df_mx_std = df_mexico.rename(columns=column_equivalences).copy()\n",
    "df_br_std = df_brazil.rename(columns=column_equivalences).copy()\n",
    "\n",
    "# 3) Chequear qué columnas siguen “solo en MX” o “solo en BR”\n",
    "set_mx = set(df_mx_std.columns)\n",
    "set_br = set(df_br_std.columns)\n",
    "solo_mx = sorted(set_mx - set_br)\n",
    "solo_br = sorted(set_br - set_mx)\n",
    "\n",
    "print(\"Columnas solo en México:\", len(solo_mx), solo_mx[:20])\n",
    "print(\"Columnas solo en Brasil:\", len(solo_br), solo_br[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a20e7-13f9-454b-b2bb-e561f9eba567",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Paso 5: Completar equivalencias que faltan\n",
    "\n",
    "**Qué unificamos ahora:**\n",
    "- `Albumin (g/dL)` ↔ `Albumin /d/dl)` → usar **Albumin (g/dL)**\n",
    "- `Time of the disease (years)` ↔ `Time of disease (years)` → usar **Time of disease (years)**\n",
    "\n",
    "**Objetivo de la comprobación:**\n",
    "Tras renombrar, que \"solo en México\" y \"solo en Brasil\" queden únicamente los\n",
    "**identificadores** (`Folio`, `Grupo` vs `Patient`, `RGHC`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876e0264-b001-4757-ac70-54623c85b89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas solo en México: 2 ['Folio', 'Grupo']\n",
      "Columnas solo en Brasil: 2 ['Patient', 'RGHC']\n"
     ]
    }
   ],
   "source": [
    "# Añadimos equivalencias que faltaban\n",
    "column_equivalences.update({\n",
    "    \"Albumin /d/dl)\": \"Albumin (g/dL)\",\n",
    "    \"Time of the disease (years)\": \"Time of disease (years)\"\n",
    "})\n",
    "\n",
    "# Reaplicar sobre copias\n",
    "df_mx_std = df_mexico.rename(columns=column_equivalences).copy()\n",
    "df_br_std = df_brazil.rename(columns=column_equivalences).copy()\n",
    "\n",
    "# Recalcular diferencias de columnas\n",
    "set_mx = set(df_mx_std.columns)\n",
    "set_br = set(df_br_std.columns)\n",
    "solo_mx = sorted(set_mx - set_br)\n",
    "solo_br = sorted(set_br - set_mx)\n",
    "\n",
    "print(\"Columnas solo en México:\", len(solo_mx), solo_mx)\n",
    "print(\"Columnas solo en Brasil:\", len(solo_br), solo_br)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1457fb-fc06-4e24-9b77-98de8dfaeeba",
   "metadata": {},
   "source": [
    "# Paso 6: Crear la columna `Country` a partir de `Center`\n",
    "\n",
    "**Por qué:** Necesitamos un indicador del país de cada paciente para análisis comparativos,\n",
    "y en tus hojas `Center` ya distingue bien:  \n",
    "- En *Mexico*: todos son `Mexico`.  \n",
    "- En *Brazil*: aparecen `Brazil` y `Spain`.\n",
    "\n",
    "**Qué haremos:**  \n",
    "1) En cada DataFrame estandarizado (`df_mx_std`, `df_br_std`), crear `Country = Center`.  \n",
    "2) Verificar frecuencias de `Country`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96bf4ede-4123-44e4-a198-c0872de188f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frecuencias de Country — México:\n",
      "Country\n",
      "Mexico    70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Frecuencias de Country — Brazil:\n",
      "Country\n",
      "Brazil    143\n",
      "Spain      77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Asignar Country directamente desde Center\n",
    "df_mx_std = df_mx_std.copy()\n",
    "df_br_std = df_br_std.copy()\n",
    "\n",
    "df_mx_std[\"Country\"] = df_mx_std[\"Center\"]\n",
    "df_br_std[\"Country\"] = df_br_std[\"Center\"]\n",
    "\n",
    "print(\"Frecuencias de Country — México:\")\n",
    "print(df_mx_std[\"Country\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nFrecuencias de Country — Brazil:\")\n",
    "print(df_br_std[\"Country\"].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687a0760-5acc-4dc3-b54b-3dd6b1365902",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Paso 7: Revisar los tipos de datos antes de concatenar\n",
    "\n",
    "**Objetivo:**  \n",
    "Confirmar que las columnas comunes entre México y Brasil tienen **el mismo tipo de dato**.\n",
    "- Si una columna es `float` en un DataFrame y `object` en otro, lo detectamos.\n",
    "- Esto nos permitirá forzar la conversión antes de concatenar, evitando problemas de formatos raros.\n",
    "\n",
    "**Qué haremos:**  \n",
    "1. Listar el número de columnas por tipo (`int64`, `float64`, `object`) en cada DataFrame.  \n",
    "2. Comparar tipos columna a columna entre México y Brasil.  \n",
    "3. Identificar las discrepancias para corregirlas en el siguiente paso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7f8df3-2b3d-40ff-8adb-5ce503859d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "México - resumen de tipos:\n",
      "float64    40\n",
      "object     32\n",
      "int64       2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Brasil - resumen de tipos:\n",
      "float64    56\n",
      "object     17\n",
      "int64       1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Columnas con tipos diferentes entre México y Brasil:\n",
      "- Albumin (g/dL): México=object, Brasil=float64\n",
      "- BMI (kg/m2): México=object, Brasil=float64\n",
      "- Bone mass (kg): México=object, Brasil=float64\n",
      "- Creatinine (mg/dL): México=object, Brasil=float64\n",
      "- Fat mass (%): México=object, Brasil=float64\n",
      "- Folic acid (ng/mL): México=object, Brasil=float64\n",
      "- HDL (mg/dL): México=object, Brasil=float64\n",
      "- Height (m): México=object, Brasil=float64\n",
      "- Hematocrit: México=object, Brasil=float64\n",
      "- Leukocytes: México=object, Brasil=float64\n",
      "- Lipid (%TEI): México=object, Brasil=float64\n",
      "- Lymphocytes: México=object, Brasil=float64\n",
      "- Metrotexato use (mg/day): México=float64, Brasil=object\n",
      "- Monocytes: México=object, Brasil=float64\n",
      "- RDW: México=object, Brasil=float64\n",
      "- Total body water (%): México=object, Brasil=float64\n",
      "- Urea (mg/dL): México=object, Brasil=float64\n",
      "- Uric acid (mg/dL): México=object, Brasil=float64\n",
      "- VCM: México=object, Brasil=float64\n",
      "- Vitamin B12 (ng/ml): México=float64, Brasil=object\n"
     ]
    }
   ],
   "source": [
    "# Resumen de tipos en cada DataFrame\n",
    "print(\"México - resumen de tipos:\")\n",
    "print(df_mx_std.dtypes.value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Brasil - resumen de tipos:\")\n",
    "print(df_br_std.dtypes.value_counts(), \"\\n\")\n",
    "\n",
    "# Comparar tipos columna a columna\n",
    "common_cols = sorted(set(df_mx_std.columns) & set(df_br_std.columns))\n",
    "diff_types = [(c, df_mx_std[c].dtype, df_br_std[c].dtype)\n",
    "              for c in common_cols if df_mx_std[c].dtype != df_br_std[c].dtype]\n",
    "\n",
    "print(\"Columnas con tipos diferentes entre México y Brasil:\")\n",
    "for col, t_mx, t_br in diff_types:\n",
    "    print(f\"- {col}: México={t_mx}, Brasil={t_br}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45fdb3-1421-42a3-9444-fc837542955f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Paso 8: Unificar tipos en columnas con discrepancias\n",
    "\n",
    "**Objetivo:** convertir a **numérico** (float) las columnas que aparecen como `object` en un DataFrame y `float` en el otro.\n",
    "\n",
    "**Cómo lo haremos:**\n",
    "- Limpiar texto típico de Excel: comas como decimales, símbolos `%`, espacios.\n",
    "- Mantener solo dígitos, signo y punto.\n",
    "- Convertir con `pd.to_numeric(errors=\"coerce\")`.\n",
    "\n",
    "**Columnas a corregir (según tu salida):**\n",
    "Albumin (g/dL), BMI (kg/m2), Bone mass (kg), Creatinine (mg/dL), Fat mass (%),\n",
    "Folic acid (ng/mL), HDL (mg/dL), Height (m), Hematocrit, Leukocytes,\n",
    "Lipid (%TEI), Lymphocytes, Metrotexato use (mg/day), Monocytes, RDW,\n",
    "Total body water (%), Urea (mg/dL), Uric acid (mg/dL), VCM, Vitamin B12 (ng/ml)\n",
    "\n",
    "> Nota: algunas aparecen como numéricas en Brasil y `object` en México, y un par al revés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8729140c-97d5-4970-9a76-6dd2b0a94a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "México - resumen tipos (post):\n",
      "float64    58\n",
      "object     14\n",
      "int64       2\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Brasil - resumen tipos (post):\n",
      "float64    58\n",
      "object     15\n",
      "int64       1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Columnas con tipos diferentes (post):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# 1) Función de limpieza -> numérico\n",
    "def clean_to_numeric(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        return series\n",
    "    s = series.astype(str)\n",
    "    s = s.str.replace(\",\", \".\", regex=False)   # coma -> punto\n",
    "    s = s.str.replace(\"%\", \"\", regex=False)    # quitar %\n",
    "    # mantener dígitos, punto, signo y notación científica\n",
    "    s = s.str.replace(r\"[^0-9eE\\+\\-\\.]\", \"\", regex=True)\n",
    "    s = s.replace({\"\": np.nan, \".\": np.nan, \"-\": np.nan, \"+\": np.nan})\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "# 2) Columnas a corregir (las de tu listado)\n",
    "cols_to_fix = [\n",
    "    \"Albumin (g/dL)\", \"BMI (kg/m2)\", \"Bone mass (kg)\", \"Creatinine (mg/dL)\",\n",
    "    \"Fat mass (%)\", \"Folic acid (ng/mL)\", \"HDL (mg/dL)\", \"Height (m)\",\n",
    "    \"Hematocrit\", \"Leukocytes\", \"Lipid (%TEI)\", \"Lymphocytes\",\n",
    "    \"Metrotexato use (mg/day)\", \"Monocytes\", \"RDW\", \"Total body water (%)\",\n",
    "    \"Urea (mg/dL)\", \"Uric acid (mg/dL)\", \"VCM\", \"Vitamin B12 (ng/ml)\"\n",
    "]\n",
    "\n",
    "# 3) Aplicar conversión en ambos DataFrames si la columna existe\n",
    "df_mx_fix = df_mx_std.copy()\n",
    "df_br_fix = df_br_std.copy()\n",
    "\n",
    "for c in cols_to_fix:\n",
    "    if c in df_mx_fix.columns:\n",
    "        df_mx_fix[c] = clean_to_numeric(df_mx_fix[c])\n",
    "    if c in df_br_fix.columns:\n",
    "        df_br_fix[c] = clean_to_numeric(df_br_fix[c])\n",
    "\n",
    "# 4) Verificación de tipos después de la conversión\n",
    "print(\"México - resumen tipos (post):\")\n",
    "print(df_mx_fix.dtypes.value_counts(), \"\\n\")\n",
    "\n",
    "print(\"Brasil - resumen tipos (post):\")\n",
    "print(df_br_fix.dtypes.value_counts(), \"\\n\")\n",
    "\n",
    "# 5) Recalcular discrepancias de tipos solo en columnas comunes\n",
    "common_cols = sorted(set(df_mx_fix.columns) & set(df_br_fix.columns))\n",
    "diff_types_post = [(c, df_mx_fix[c].dtype, df_br_fix[c].dtype)\n",
    "                   for c in common_cols if df_mx_fix[c].dtype != df_br_fix[c].dtype]\n",
    "\n",
    "print(\"Columnas con tipos diferentes (post):\")\n",
    "for col, t_mx, t_br in diff_types_post:\n",
    "    print(f\"- {col}: México={t_mx}, Brasil={t_br}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2bd93c-3d02-42eb-89ff-6e80cc38012f",
   "metadata": {},
   "source": [
    "# Paso 9: Concatenar México + Brasil y verificar\n",
    "\n",
    "**Objetivo:** crear el dataset maestro `df_master` ya con tipos alineados.\n",
    "\n",
    "**Verificaciones tras concatenar:**\n",
    "- `shape` esperado ≈ (290, Nº columnas comunes + identificadores + Country)\n",
    "- `Country` con 3 niveles: Mexico / Brazil / Spain\n",
    "- Sin columnas duplicadas en nombre\n",
    "- Recuento de tipos en el combinado (object vs float vs int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c72caa0-c370-4c96-8734-bb2c5203a3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape combinado: (290, 76)\n",
      "Columnas duplicadas: []\n",
      "Valores únicos en 'Country': ['Mexico' 'Brazil' 'Spain']\n",
      "Frecuencias 'Country':\n",
      "Country\n",
      "Brazil    143\n",
      "Spain      77\n",
      "Mexico     70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Tipos en combinado:\n",
      "float64    59\n",
      "object     16\n",
      "int64       1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Concatenar\n",
    "df_master = pd.concat([df_mx_fix, df_br_fix], ignore_index=True)\n",
    "\n",
    "# 2) Checks\n",
    "print(\"Shape combinado:\", df_master.shape)\n",
    "\n",
    "dups = df_master.columns[df_master.columns.duplicated()].tolist()\n",
    "print(\"Columnas duplicadas:\", dups)\n",
    "\n",
    "print(\"Valores únicos en 'Country':\", df_master[\"Country\"].unique())\n",
    "print(\"Frecuencias 'Country':\")\n",
    "print(df_master[\"Country\"].value_counts(dropna=False))\n",
    "\n",
    "print(\"\\nTipos en combinado:\")\n",
    "print(df_master.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7476d5f7-4c70-4720-bf9b-4e50bb0a2240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folio</th>\n",
       "      <th>Grupo</th>\n",
       "      <th>Center</th>\n",
       "      <th>Race</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age (years)</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Education level</th>\n",
       "      <th>Smoking habits</th>\n",
       "      <th>Time of disease (years)</th>\n",
       "      <th>HCQ use (mg/day)</th>\n",
       "      <th>HCQ use (mg/kg/day)</th>\n",
       "      <th>Corticoide use (mg/day)</th>\n",
       "      <th>Metrotexato use (mg/day)</th>\n",
       "      <th>SLICC</th>\n",
       "      <th>SLEDAI</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (m)</th>\n",
       "      <th>BMI (kg/m2)</th>\n",
       "      <th>Waist Circ (cm)</th>\n",
       "      <th>Fat mass (kg)</th>\n",
       "      <th>Fat mass (%)</th>\n",
       "      <th>Fat free mass (kg)</th>\n",
       "      <th>Fat free mass (%)</th>\n",
       "      <th>Bone mass (kg)</th>\n",
       "      <th>Total body water (%)</th>\n",
       "      <th>Systolic Blood Pressure (mm/Hg)</th>\n",
       "      <th>Diastolic Blood Pressure (mm/Hg)</th>\n",
       "      <th>Glucose (mg/dL)</th>\n",
       "      <th>Total cholesterol (mg/dL)</th>\n",
       "      <th>LDL (mg/dL)</th>\n",
       "      <th>HDL (mg/dL)</th>\n",
       "      <th>n-HDL (mg/dL)</th>\n",
       "      <th>VLDL (mg/dL)</th>\n",
       "      <th>Triglycerides (mg/dL)</th>\n",
       "      <th>C-reactive protein</th>\n",
       "      <th>Albumin (g/dL)</th>\n",
       "      <th>Uric acid (mg/dL)</th>\n",
       "      <th>Insuline (U/ml)</th>\n",
       "      <th>GOT_AST (U/L)</th>\n",
       "      <th>GPT_ALT (U/L)</th>\n",
       "      <th>Urea (mg/dL)</th>\n",
       "      <th>Creatinine (mg/dL)</th>\n",
       "      <th>Folic acid (ng/mL)</th>\n",
       "      <th>Vitamin B12 (ng/ml)</th>\n",
       "      <th>Vitamin D (ng/mL)</th>\n",
       "      <th>Leukocytes</th>\n",
       "      <th>Neutrophils</th>\n",
       "      <th>Lymphocytes</th>\n",
       "      <th>Monocytes</th>\n",
       "      <th>Platelets</th>\n",
       "      <th>Hemoglobin</th>\n",
       "      <th>Hematocrit</th>\n",
       "      <th>VCM</th>\n",
       "      <th>CHCM</th>\n",
       "      <th>RDW</th>\n",
       "      <th>VSG (mm)</th>\n",
       "      <th>C3 complement</th>\n",
       "      <th>C4 complement</th>\n",
       "      <th>Anti-dsDNA</th>\n",
       "      <th>TyG</th>\n",
       "      <th>Energy intake (kcal/day)</th>\n",
       "      <th>Carbohydrate intake (g/day)</th>\n",
       "      <th>Carbohydrate intake (%TEI)</th>\n",
       "      <th>Protein intake (g/day)</th>\n",
       "      <th>Protein intake (%TEI)</th>\n",
       "      <th>Lipid intake (g/day)</th>\n",
       "      <th>Lipid (%TEI)</th>\n",
       "      <th>METs-min/week</th>\n",
       "      <th>IPAQ</th>\n",
       "      <th>FACIT Fatigue Scale</th>\n",
       "      <th>PCS12 (HRQoL)</th>\n",
       "      <th>MCS12 (HRQoL)</th>\n",
       "      <th>Country</th>\n",
       "      <th>Patient</th>\n",
       "      <th>RGHC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexican-Mestizo</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>married</td>\n",
       "      <td>Incomplete academic degree</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>95.9</td>\n",
       "      <td>1.61</td>\n",
       "      <td>36.9</td>\n",
       "      <td>111.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>75.00</td>\n",
       "      <td>175.00</td>\n",
       "      <td>73.80</td>\n",
       "      <td>40.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>306.00</td>\n",
       "      <td>8.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3265</td>\n",
       "      <td>11.63</td>\n",
       "      <td>73.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>261.0</td>\n",
       "      <td>45880.00</td>\n",
       "      <td>39.90</td>\n",
       "      <td>39.90</td>\n",
       "      <td>89.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.0</td>\n",
       "      <td>23</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1158353.0</td>\n",
       "      <td>169554.0</td>\n",
       "      <td>5855003.0</td>\n",
       "      <td>5109967.00</td>\n",
       "      <td>1764563</td>\n",
       "      <td>3478867.0</td>\n",
       "      <td>2702959.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sedentar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexican-Mestizo</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>married</td>\n",
       "      <td>Incomplete academic degree</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>1.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.2</td>\n",
       "      <td>102.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>79.00</td>\n",
       "      <td>112.00</td>\n",
       "      <td>59.35</td>\n",
       "      <td>23.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.68</td>\n",
       "      <td>15.92</td>\n",
       "      <td>3.44</td>\n",
       "      <td>5.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>5775.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.16</td>\n",
       "      <td>4.36</td>\n",
       "      <td>79.75</td>\n",
       "      <td>14.23</td>\n",
       "      <td>3.67</td>\n",
       "      <td>344.5</td>\n",
       "      <td>45725.00</td>\n",
       "      <td>28.49</td>\n",
       "      <td>28.49</td>\n",
       "      <td>90.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2260957.0</td>\n",
       "      <td>3014973.0</td>\n",
       "      <td>5333977.0</td>\n",
       "      <td>9760267.00</td>\n",
       "      <td>172675</td>\n",
       "      <td>7802666.0</td>\n",
       "      <td>3105941.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sedentar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexican-Mestizo</td>\n",
       "      <td>Female</td>\n",
       "      <td>66</td>\n",
       "      <td>widow</td>\n",
       "      <td>Incomplete academic degree</td>\n",
       "      <td>No</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.9</td>\n",
       "      <td>1.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.4</td>\n",
       "      <td>137.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>124.98</td>\n",
       "      <td>198.99</td>\n",
       "      <td>126.34</td>\n",
       "      <td>51.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.04</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>6659.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.27</td>\n",
       "      <td>6.69</td>\n",
       "      <td>43.78</td>\n",
       "      <td>46.45</td>\n",
       "      <td>6.16</td>\n",
       "      <td>231.8</td>\n",
       "      <td>13.28</td>\n",
       "      <td>42.61</td>\n",
       "      <td>42.61</td>\n",
       "      <td>98.75</td>\n",
       "      <td>31.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>143.5</td>\n",
       "      <td>16.59</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1043054.0</td>\n",
       "      <td>1290997.0</td>\n",
       "      <td>4950835.0</td>\n",
       "      <td>41.39</td>\n",
       "      <td>1587262</td>\n",
       "      <td>3475033.0</td>\n",
       "      <td>2998435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sedentar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexican-Mestizo</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>Incomplete academic degree</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>1.64</td>\n",
       "      <td>27.0</td>\n",
       "      <td>93.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>86.93</td>\n",
       "      <td>113.45</td>\n",
       "      <td>54.07</td>\n",
       "      <td>38.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.16</td>\n",
       "      <td>2025-12-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6889.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>786519.0</td>\n",
       "      <td>109732.0</td>\n",
       "      <td>5580641.0</td>\n",
       "      <td>31684.00</td>\n",
       "      <td>1611353</td>\n",
       "      <td>2495933.0</td>\n",
       "      <td>2856053.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Activo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Paciente</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Mexican-Mestizo</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>single</td>\n",
       "      <td>Incomplete academic degree</td>\n",
       "      <td>No</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.1</td>\n",
       "      <td>1.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.6</td>\n",
       "      <td>114.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>97.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>78.57</td>\n",
       "      <td>66.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.00</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25278.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6718.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.40</td>\n",
       "      <td>52.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>45852.00</td>\n",
       "      <td>47.60</td>\n",
       "      <td>47.60</td>\n",
       "      <td>91.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1712115.0</td>\n",
       "      <td>231027.0</td>\n",
       "      <td>5397464.0</td>\n",
       "      <td>7508567.00</td>\n",
       "      <td>175422</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2770258.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sedentar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Folio     Grupo  Center             Race  Gender  Age (years) Marital status             Education level Smoking habits  \\\n",
       "0    1.0  Paciente  Mexico  Mexican-Mestizo  Female           29        married  Incomplete academic degree             No   \n",
       "1    2.0  Paciente  Mexico  Mexican-Mestizo  Female           24        married  Incomplete academic degree             No   \n",
       "2    3.0  Paciente  Mexico  Mexican-Mestizo  Female           66          widow  Incomplete academic degree             No   \n",
       "3    4.0  Paciente  Mexico  Mexican-Mestizo  Female           29         single  Incomplete academic degree            yes   \n",
       "4    5.0  Paciente  Mexico  Mexican-Mestizo  Female           40         single  Incomplete academic degree             No   \n",
       "\n",
       "   Time of disease (years)  HCQ use (mg/day)  HCQ use (mg/kg/day)  Corticoide use (mg/day)  Metrotexato use (mg/day)  SLICC  SLEDAI  \\\n",
       "0                      4.0               NaN                  NaN                      NaN                       NaN    0.0     4.0   \n",
       "1                      4.0               NaN                  NaN                      NaN                       NaN    0.0     0.0   \n",
       "2                     16.0               NaN                  NaN                      NaN                       NaN    4.0     0.0   \n",
       "3                      1.0               NaN                  NaN                      NaN                       NaN    1.0     4.0   \n",
       "4                     13.0               NaN                  NaN                      NaN                       NaN    1.0     0.0   \n",
       "\n",
       "   Weight (kg)  Height (m)  BMI (kg/m2)  Waist Circ (cm)  Fat mass (kg)  Fat mass (%)  Fat free mass (kg)  Fat free mass (%)  \\\n",
       "0         95.9        1.61         36.9            111.1            NaN          46.9                 NaN                NaN   \n",
       "1         41.6        1.54          NaN             65.5            NaN           NaN                 NaN                NaN   \n",
       "2         67.9        1.49          NaN             93.7            NaN          39.8                 NaN                NaN   \n",
       "3         72.7        1.64         27.0             93.5            NaN          33.2                 NaN                NaN   \n",
       "4         60.1        1.62          NaN             79.8            NaN           NaN                 NaN                NaN   \n",
       "\n",
       "   Bone mass (kg)  Total body water (%)  Systolic Blood Pressure (mm/Hg)  Diastolic Blood Pressure (mm/Hg)  Glucose (mg/dL)  \\\n",
       "0             NaN                  39.0                            143.0                              66.0            75.00   \n",
       "1             2.0                  63.2                            102.0                              63.0            79.00   \n",
       "2             NaN                  41.4                            137.0                              77.0           124.98   \n",
       "3             NaN                  47.4                            122.0                              78.0            86.93   \n",
       "4             NaN                  47.6                            114.0                              77.0            97.00   \n",
       "\n",
       "   Total cholesterol (mg/dL)  LDL (mg/dL)  HDL (mg/dL)  n-HDL (mg/dL)  VLDL (mg/dL)  Triglycerides (mg/dL)   C-reactive protein  \\\n",
       "0                     175.00        73.80        40.00            NaN           NaN                 306.00                 8.51   \n",
       "1                     112.00        59.35        23.82            NaN           NaN                 106.68                15.92   \n",
       "2                     198.99       126.34        51.13            NaN           NaN                 119.04                 3.59   \n",
       "3                     113.45        54.07        38.43            NaN           NaN                 137.16  2025-12-14 00:00:00   \n",
       "4                     157.00        78.57        66.67            NaN           NaN                  66.00                 3.19   \n",
       "\n",
       "   Albumin (g/dL)  Uric acid (mg/dL)  Insuline (U/ml)  GOT_AST (U/L)  GPT_ALT (U/L)  Urea (mg/dL)  Creatinine (mg/dL)  Folic acid (ng/mL)  \\\n",
       "0             NaN               7.96              NaN            NaN            NaN          35.3                 NaN              8444.0   \n",
       "1            3.44               5.54              NaN            NaN            NaN          27.0                0.61              5775.0   \n",
       "2            3.87                NaN              NaN            NaN            NaN          48.0                0.97              6659.0   \n",
       "3             NaN                NaN              NaN            NaN            NaN           NaN                 NaN              6889.0   \n",
       "4            3.72                NaN              NaN            NaN            NaN       25278.0                0.90              6718.0   \n",
       "\n",
       "   Vitamin B12 (ng/ml) Vitamin D (ng/mL)  Leukocytes  Neutrophils  Lymphocytes  Monocytes  Platelets  Hemoglobin  Hematocrit    VCM  \\\n",
       "0                  NaN              3265       11.63        73.70          NaN        NaN      261.0    45880.00       39.90  39.90   \n",
       "1                  NaN             14.16        4.36        79.75        14.23       3.67      344.5    45725.00       28.49  28.49   \n",
       "2                  NaN             27.27        6.69        43.78        46.45       6.16      231.8       13.28       42.61  42.61   \n",
       "3                  NaN             33.27         NaN          NaN          NaN        NaN        NaN         NaN         NaN    NaN   \n",
       "4                  NaN             25.13         NaN        38.40        52.70        NaN      210.0    45852.00       47.60  47.60   \n",
       "\n",
       "    CHCM    RDW  VSG (mm)  C3 complement C4 complement Anti-dsDNA  TyG  Energy intake (kcal/day)  Carbohydrate intake (g/day)  \\\n",
       "0  89.10    NaN       NaN          118.0            23          P  NaN                 1158353.0                     169554.0   \n",
       "1  90.69    NaN       NaN            NaN           NaN          P  NaN                 2260957.0                    3014973.0   \n",
       "2  98.75  31.17       NaN          143.5         16.59          N  NaN                 1043054.0                    1290997.0   \n",
       "3    NaN    NaN       NaN            NaN           NaN          P  NaN                  786519.0                     109732.0   \n",
       "4  91.20    NaN       NaN            NaN           NaN          N  NaN                 1712115.0                     231027.0   \n",
       "\n",
       "   Carbohydrate intake (%TEI)  Protein intake (g/day) Protein intake (%TEI)  Lipid intake (g/day)  Lipid (%TEI)  METs-min/week      IPAQ  \\\n",
       "0                   5855003.0              5109967.00               1764563             3478867.0     2702959.0            NaN  Sedentar   \n",
       "1                   5333977.0              9760267.00                172675             7802666.0     3105941.0            NaN  Sedentar   \n",
       "2                   4950835.0                   41.39               1587262             3475033.0     2998435.0            NaN  Sedentar   \n",
       "3                   5580641.0                31684.00               1611353             2495933.0     2856053.0            NaN    Activo   \n",
       "4                   5397464.0              7508567.00                175422                  52.7     2770258.0            NaN  Sedentar   \n",
       "\n",
       "   FACIT Fatigue Scale  PCS12 (HRQoL)  MCS12 (HRQoL) Country Patient RGHC  \n",
       "0                  NaN            NaN            NaN  Mexico     NaN  NaN  \n",
       "1                  NaN            NaN            NaN  Mexico     NaN  NaN  \n",
       "2                  NaN            NaN            NaN  Mexico     NaN  NaN  \n",
       "3                  NaN            NaN            NaN  Mexico     NaN  NaN  \n",
       "4                  NaN            NaN            NaN  Mexico     NaN  NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97388614-a93a-4d1d-9beb-ae81cda8a5aa",
   "metadata": {},
   "source": [
    "# Paso 10: Exportar el dataset maestro\n",
    "\n",
    "**Formato recomendado:**  \n",
    "- **CSV** → seguro para análisis y evita problemas de formato (Excel no interpreta como fechas).  \n",
    "- **Excel** → solo como copia de cortesía (si ves \"#####\" ensancha la columna; si ves \"fechas\", cambia formato a Número/General).\n",
    "\n",
    "**Archivos a crear:**  \n",
    "- `outputs/dataset_master_v3.csv`  \n",
    "- `outputs/dataset_master_v3.xlsx`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3117cab-82cd-447a-9070-90618a912e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado CSV: C:\\Users\\manue\\TFM MÁSTER BIOINFORMÁTICA\\outputs\\dataset_master_v3.csv\n",
      "Exportado Excel: C:\\Users\\manue\\TFM MÁSTER BIOINFORMÁTICA\\outputs\\dataset_master_v3.xlsx\n",
      "Shape al reabrir CSV: (290, 76)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Crear carpeta de salida\n",
    "out_dir = Path(\"outputs\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Rutas\n",
    "csv_out = out_dir / \"dataset_master_v3.csv\"\n",
    "xlsx_out = out_dir / \"dataset_master_v3.xlsx\"\n",
    "\n",
    "# Exportar CSV (canon para trabajar)\n",
    "df_master.to_csv(csv_out, index=False)\n",
    "\n",
    "# Exportar Excel (solo copia)\n",
    "with pd.ExcelWriter(xlsx_out, engine=\"openpyxl\") as writer:\n",
    "    df_master.to_excel(writer, sheet_name=\"master\", index=False)\n",
    "\n",
    "print(\"Exportado CSV:\", csv_out.resolve())\n",
    "print(\"Exportado Excel:\", xlsx_out.resolve())\n",
    "\n",
    "# Verificación rápida al reabrir CSV\n",
    "df_check = pd.read_csv(csv_out)\n",
    "print(\"Shape al reabrir CSV:\", df_check.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c1b558d-737b-403e-aaf0-27464a7fa9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 valores en Hemoglobin\n",
      "69    46005.0\n",
      "63    46004.0\n",
      "64    46003.0\n",
      "8     45975.0\n",
      "37    45972.0\n",
      "22    45916.0\n",
      "15    45915.0\n",
      "56    45912.0\n",
      "7     45911.0\n",
      "20    45882.0\n",
      "Name: Hemoglobin, dtype: float64\n",
      "\n",
      "Muestra aleatoria (10):\n",
      "102       12.80\n",
      "19     45787.00\n",
      "189       13.00\n",
      "69     46005.00\n",
      "259       14.00\n",
      "56     45912.00\n",
      "209       12.00\n",
      "194       11.20\n",
      "12        11.87\n",
      "100       12.10\n",
      "Name: Hemoglobin, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1) Ver los 10 mayores en Hemoglobin (o la columna que tú veas mal)\n",
    "col = \"Hemoglobin\"\n",
    "print(\"Top 10 valores en\", col)\n",
    "print(df_master[col].sort_values(ascending=False).head(10))\n",
    "\n",
    "# 2) Ver 10 valores al azar para comparar\n",
    "print(\"\\nMuestra aleatoria (10):\")\n",
    "print(df_master[col].dropna().sample(min(10, df_master[col].notna().sum()), random_state=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcff72-20ca-4b87-a45f-1b4c95daf1fb",
   "metadata": {},
   "source": [
    "# Paso B: Corregir valores mal interpretados (prueba con Hemoglobin)\n",
    "\n",
    "**Problema:** valores como 45.911 se transformaron en 45911 al perder el separador decimal.\n",
    "\n",
    "**Solución:** función `parse_locale_number` que:\n",
    "- Reconoce separador de miles (12.345 → 12345).\n",
    "- Reconoce coma como decimal (12,3 → 12.3).\n",
    "- Convierte a float manteniendo decimales.\n",
    "\n",
    "**Prueba:** aplicamos a `Hemoglobin` y comparamos original vs corregido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1835abe-155b-43b9-971a-04b6d6839b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación original vs corregido (valores grandes):\n",
      "    Hemoglobin  Hemoglobin_fix\n",
      "0      45880.0         45880.0\n",
      "1      45725.0         45725.0\n",
      "4      45852.0         45852.0\n",
      "5      45761.0         45761.0\n",
      "6      45725.0         45725.0\n",
      "7      45911.0         45911.0\n",
      "8      45975.0         45975.0\n",
      "9      45789.0         45789.0\n",
      "11     45819.0         45819.0\n",
      "13     45702.0         45702.0\n",
      "\n",
      "Resumen de Hemoglobin_fix:\n",
      "count      276.000000\n",
      "mean      5324.684058\n",
      "std      14694.063241\n",
      "min          0.090000\n",
      "25%         12.400000\n",
      "50%         13.400000\n",
      "75%         14.400000\n",
      "max      46005.000000\n",
      "Name: Hemoglobin_fix, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def parse_locale_number(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "\n",
    "    # Caso simple: ya es float válido\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    # Caso con punto y coma -> formato europeo\n",
    "    if \".\" in s and \",\" in s:\n",
    "        s = s.replace(\".\", \"\").replace(\",\", \".\")\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # Solo comas -> decimal\n",
    "    if \",\" in s:\n",
    "        s = s.replace(\",\", \".\")\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # Solo puntos\n",
    "    if \".\" in s:\n",
    "        # Patrón de miles (grupos de 3 dígitos)\n",
    "        if re.fullmatch(r\"\\d{1,3}(?:\\.\\d{3})+\", s):\n",
    "            s = s.replace(\".\", \"\")\n",
    "            return pd.to_numeric(s, errors=\"coerce\")\n",
    "        else:\n",
    "            return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # Último recurso: limpiar caracteres\n",
    "    s = re.sub(r\"[^0-9\\.\\-]\", \"\", s)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "# Aplicar SOLO a Hemoglobin (prueba)\n",
    "df_master[\"Hemoglobin_fix\"] = df_master[\"Hemoglobin\"].apply(parse_locale_number)\n",
    "\n",
    "print(\"Comparación original vs corregido (valores grandes):\")\n",
    "print(df_master.loc[df_master[\"Hemoglobin\"] > 1000, [\"Hemoglobin\", \"Hemoglobin_fix\"]].head(10))\n",
    "\n",
    "print(\"\\nResumen de Hemoglobin_fix:\")\n",
    "print(df_master[\"Hemoglobin_fix\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0130e57-a4e5-4fdb-b76b-9d5548e77057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos antes de convertir (df_mx_std): float64\n",
      "\n",
      "Ejemplo de valores originales en df_mx_std['Hemoglobin'] (10 al azar):\n",
      "[45853.0, 12.23, 45912.0, 45668.0, 10.98, 13.28, 45916.0, 16.33, 14.38, 45786.0]\n"
     ]
    }
   ],
   "source": [
    "# Ver cómo está Hemoglobin en el DataFrame ANTES de la conversión\n",
    "print(\"Tipos antes de convertir (df_mx_std):\", df_mx_std[\"Hemoglobin\"].dtype)\n",
    "print(\"\\nEjemplo de valores originales en df_mx_std['Hemoglobin'] (10 al azar):\")\n",
    "print(df_mx_std[\"Hemoglobin\"].dropna().sample(10, random_state=1).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc822e6-2c45-4096-bf90-026122766487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra cruda (texto) desde Excel → Mexico['Hemoglobin']:\n",
      "{'Hemoglobin': ['45880', '45725', '13.28', nan, '45852', '45761', '45725', '45911', '45975', '45789']}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_mx_fix (actual)</th>\n",
       "      <th>excel_texto (releído)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45880.00</td>\n",
       "      <td>45880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45725.00</td>\n",
       "      <td>45725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.28</td>\n",
       "      <td>13.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45852.00</td>\n",
       "      <td>45852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45761.00</td>\n",
       "      <td>45761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45725.00</td>\n",
       "      <td>45725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>45911.00</td>\n",
       "      <td>45911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45975.00</td>\n",
       "      <td>45975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45789.00</td>\n",
       "      <td>45789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   df_mx_fix (actual) excel_texto (releído)\n",
       "0            45880.00                 45880\n",
       "1            45725.00                 45725\n",
       "2               13.28                 13.28\n",
       "3                 NaN                   NaN\n",
       "4            45852.00                 45852\n",
       "5            45761.00                 45761\n",
       "6            45725.00                 45725\n",
       "7            45911.00                 45911\n",
       "8            45975.00                 45975\n",
       "9            45789.00                 45789"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Releer desde el Excel original SOLO la columna Hemoglobin de la hoja \"Mexico\", como TEXTO\n",
    "mx_hemo_raw = pd.read_excel(\"Datos Brasil, España, Mexico.xlsx\",\n",
    "                            sheet_name=\"Mexico\",\n",
    "                            usecols=[\"Hemoglobin\"],\n",
    "                            dtype=str)\n",
    "\n",
    "print(\"Muestra cruda (texto) desde Excel → Mexico['Hemoglobin']:\")\n",
    "print(mx_hemo_raw.head(10).to_dict(orient=\"list\"))\n",
    "\n",
    "# 2) Mostrar lado a lado (primero 10 filas) lo que tienes en df_mx_fix vs lo recién leído como texto\n",
    "comp = pd.DataFrame({\n",
    "    \"df_mx_fix (actual)\": df_mx_fix[\"Hemoglobin\"].head(10).tolist(),\n",
    "    \"excel_texto (releído)\": mx_hemo_raw[\"Hemoglobin\"].head(10).tolist(),\n",
    "})\n",
    "comp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcc2e209-a7a7-484c-94b8-52df2dba84fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: Hemoglobin\n",
      "  No nulos totales: 276\n",
      "  Valores en rango [5.0, 20.0]: 243\n",
      "  Valores improbables (fuera de rango): 33\n",
      "\n",
      "Ejemplos de valores improbables (primeros 10):\n",
      "    Hemoglobin Country\n",
      "0     45880.00  Mexico\n",
      "1     45725.00  Mexico\n",
      "4     45852.00  Mexico\n",
      "5     45761.00  Mexico\n",
      "6     45725.00  Mexico\n",
      "7     45911.00  Mexico\n",
      "8     45975.00  Mexico\n",
      "9     45789.00  Mexico\n",
      "10        0.09  Mexico\n",
      "11    45819.00  Mexico\n",
      "\n",
      "Muestra del informe QC (posibles seriales de fecha):\n",
      "    Hemoglobin Country excel_like_date\n",
      "0     45880.00  Mexico      2025-08-11\n",
      "1     45725.00  Mexico      2025-03-09\n",
      "4     45852.00  Mexico      2025-07-14\n",
      "5     45761.00  Mexico      2025-04-14\n",
      "6     45725.00  Mexico      2025-03-09\n",
      "7     45911.00  Mexico      2025-09-11\n",
      "8     45975.00  Mexico      2025-11-14\n",
      "9     45789.00  Mexico      2025-05-12\n",
      "10        0.09  Mexico             NaN\n",
      "11    45819.00  Mexico      2025-06-11\n",
      "\n",
      "Conteo de filas con 'excel_like_date' no nulo: 32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Copiamos solo para inspección\n",
    "col = \"Hemoglobin\"\n",
    "\n",
    "# Rango plausible (ajústalo si tu clínica usa otros umbrales)\n",
    "lower, upper = 5.0, 20.0\n",
    "\n",
    "s = df_master[col]\n",
    "# Valores no nulos que caen fuera del rango razonable\n",
    "mask_improbable = s.notna() & ((s < lower) | (s > upper))\n",
    "\n",
    "n_total = s.notna().sum()\n",
    "n_bad = mask_improbable.sum()\n",
    "n_ok = n_total - n_bad\n",
    "\n",
    "print(f\"Columna: {col}\")\n",
    "print(f\"  No nulos totales: {n_total}\")\n",
    "print(f\"  Valores en rango [{lower}, {upper}]: {n_ok}\")\n",
    "print(f\"  Valores improbables (fuera de rango): {n_bad}\")\n",
    "\n",
    "# Ver algunos ejemplos de valores improbables\n",
    "ejemplos = df_master.loc[mask_improbable, [col, \"Country\"]].head(10)\n",
    "print(\"\\nEjemplos de valores improbables (primeros 10):\")\n",
    "print(ejemplos)\n",
    "\n",
    "# Mini-informe de calidad: intentamos inferir si el número \"parece\" un serial de fecha de Excel\n",
    "# Excel (Windows) tiene origen 1899-12-30; 1 -> 1899-12-31. Seriales ~ 45000 son 2023-2025.\n",
    "excel_epoch = datetime(1899, 12, 30)\n",
    "\n",
    "def maybe_excel_date(n):\n",
    "    try:\n",
    "        if 20000 <= float(n) <= 60000:\n",
    "            return (excel_epoch + timedelta(days=float(n))).date().isoformat()\n",
    "        else:\n",
    "            return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "qc_issues = df_master.loc[mask_improbable, [col, \"Country\"]].copy()\n",
    "qc_issues[\"excel_like_date\"] = qc_issues[col].apply(maybe_excel_date)\n",
    "\n",
    "print(\"\\nMuestra del informe QC (posibles seriales de fecha):\")\n",
    "print(qc_issues.head(10))\n",
    "print(\"\\nConteo de filas con 'excel_like_date' no nulo:\", qc_issues[\"excel_like_date\"].notna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17d018-5bc8-4b88-bd6c-0faccd54090d",
   "metadata": {},
   "source": [
    "# Paso C: Saneamiento de Hemoglobin\n",
    "\n",
    "**Qué haremos:**\n",
    "- Detectar valores fuera del rango [5–20] g/dL.\n",
    "- Sustituirlos por `NaN` en `Hemoglobin_clean`.\n",
    "- Generar un informe `hemoglobin_qc.csv` con esos casos, incluyendo la fecha probable que Excel había metido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51867fae-854d-4bb4-a523-05ef4847e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado informe QC en: C:\\Users\\manue\\TFM MÁSTER BIOINFORMÁTICA\\outputs\\hemoglobin_qc.csv\n",
      "Resumen de Hemoglobin_clean:\n",
      "count    243.000000\n",
      "mean      13.048189\n",
      "std        1.497947\n",
      "min        8.310000\n",
      "25%       12.255000\n",
      "50%       13.200000\n",
      "75%       14.000000\n",
      "max       17.100000\n",
      "Name: Hemoglobin_clean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "col = \"Hemoglobin\"\n",
    "lower, upper = 5.0, 20.0\n",
    "\n",
    "# Creamos columna corregida\n",
    "df_master[col + \"_clean\"] = df_master[col].where(\n",
    "    (df_master[col].between(lower, upper)) | (df_master[col].isna()), \n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Informe QC para trazabilidad\n",
    "qc_issues = df_master.loc[df_master[col + \"_clean\"].isna() & df_master[col].notna(),\n",
    "                          [col, \"Country\"]].copy()\n",
    "qc_issues[\"excel_like_date\"] = qc_issues[col].apply(maybe_excel_date)\n",
    "\n",
    "# Guardamos informe\n",
    "out_dir = Path(\"outputs\"); out_dir.mkdir(exist_ok=True)\n",
    "qc_path = out_dir / \"hemoglobin_qc.csv\"\n",
    "qc_issues.to_csv(qc_path, index=False)\n",
    "\n",
    "print(\"Guardado informe QC en:\", qc_path.resolve())\n",
    "print(\"Resumen de Hemoglobin_clean:\")\n",
    "print(df_master[col + \"_clean\"].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb371c-b53d-4d00-a743-7423dcb41bba",
   "metadata": {},
   "source": [
    "# Paso D: Exportar dataset maestro con correcciones\n",
    "\n",
    "**Qué incluimos:**\n",
    "- Todas las columnas originales.\n",
    "- + Columnas *_clean para variables corregidas (por ahora solo Hemoglobin).\n",
    "\n",
    "**Archivos:**\n",
    "- `outputs/dataset_master_clean.csv` → formato canon (seguro).\n",
    "- `outputs/dataset_master_clean.xlsx` → copia para Excel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b5c0830-708a-4daa-b9f1-d463e72f55fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportado CSV: C:\\Users\\manue\\TFM MÁSTER BIOINFORMÁTICA\\outputs\\dataset_master_clean.csv\n",
      "Exportado Excel: C:\\Users\\manue\\TFM MÁSTER BIOINFORMÁTICA\\outputs\\dataset_master_clean.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Exportar dataset con columnas originales + Hemoglobin_clean\n",
    "csv_out = out_dir / \"dataset_master_clean.csv\"\n",
    "xlsx_out = out_dir / \"dataset_master_clean.xlsx\"\n",
    "\n",
    "df_master.to_csv(csv_out, index=False)\n",
    "\n",
    "with pd.ExcelWriter(xlsx_out, engine=\"openpyxl\") as writer:\n",
    "    df_master.to_excel(writer, sheet_name=\"master\", index=False)\n",
    "\n",
    "print(\"Exportado CSV:\", csv_out.resolve())\n",
    "print(\"Exportado Excel:\", xlsx_out.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154ff8e-536f-4dac-90a4-e7b6169a815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
